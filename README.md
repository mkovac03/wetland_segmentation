# Wetland Segmentation with ResUNet-ViT

This project performs high-resolution semantic segmentation of wetlands across Europe using a hybrid CNN-ViT architecture trained on 10-meter satellite imagery. It addresses the challenge of weak supervision from coarse-resolution 100-meter labels by applying label-aware loss weighting and boundary enhancement strategies to sharpen spatial accuracy at the native 10â€¯m scale. The dataset exhibits strong class imbalance, which is handled through a combination of focal and class-weighted loss functions, improving minority class detection. It uses weak supervision from 100-meter wetland type labels and powerful spectral-temporal embeddings from Googleâ€™s Earth Engine dataset.

---

## ğŸŒ Datasets

### ğŸ£ Weak Supervision Labels

* **Source**: European Environment Agency (EEA)
* **Dataset**: [Wetland Types Dataset on EEA DataHub](https://www.eea.europa.eu/en/datahub/datahubitem-view/b9399908-557a-47a8-954a-958dabeaf1b6)
* **Coverage**: Europe-wide (all EU member states + cooperating regions)
* **Format**: Rasterized to 100-meter resolution (FAO Level-3 Wetland Types)
* **Wetland Classes**:

  * No Wetland
  * Rice Fields
  * Riparian, fluvial and swamp broadleaved forest
  * Riparian, fluvial and swamp coniferous forest
  * Riparian, fluvial and mixed forest
  * Managed or grazed wet meadow or pasture
  * Natural seasonally or permanently wet grasslands
  * Wet heaths
  * Riverine and fen scrubs
  * Beaches, dunes, sand
  * Inland marshes
  * Open mires
  * Salt marshes
  * Coastal lagoons
  * River estuaries and estuarine waters of deltas
  * Coastal saltpans (highly artificial salinas)
  * Intertidal flats
  * Surface water

### ğŸ›‹ï¸ Input Features

* **Source**: [Google Earth Engine â€“ Satellite Embedding v1](https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_SATELLITE_EMBEDDING_V1_ANNUAL)
* **Description**:

  * Global 64-band spectral-temporal embedding trained via contrastive learning
  * Derived from Sentinel-1, Sentinel-2, and Landsat time series
* **Resolution**: 10â€¯m
* **Coverage**: Europe-wide
* **Selected Features**:

  * 29 pre-selected image channels
  * Selected based on mean feature importance across experiments

---

## ğŸ“¦ Project Structure

```bash
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml              # Main configuration file (with {now} placeholders)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ preprocess.py            # Reprojects, resamples, and remaps raster inputs
â”‚   â”œâ”€â”€ split_data.py            # Generates train/val/test splits
â”‚   â”œâ”€â”€ dataset.py               # PyTorch dataset class (loads .npy tiles)
â”‚   â””â”€â”€ transform.py             # Random flip/rotate augmentation
â”œâ”€â”€ models/
â”‚   â””â”€â”€ resunet_vit.py           # Hybrid ResNet+ViT architecture
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ train.py                 # Main training script
â”‚   â”œâ”€â”€ metrics.py               # Computes mIoU, F1, etc.
â”‚   â””â”€â”€ losses/
â”‚       â”œâ”€â”€ focal_tversky.py     # Custom Focal + Tversky loss with boundary masking
â”‚       â””â”€â”€ soft_boundary_dice.py# Optional soft boundary-aware Dice loss
â”œâ”€â”€ predict/
â”‚   â”œâ”€â”€ inference.py             # Patch-based inference with label remapping
â”‚   â””â”€â”€ evaluate_predictions.py  # Confusion matrix, metrics CSV
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_train.sh             # Bash script to run preprocessing + training
â”‚   â”œâ”€â”€ build_vrt.py             # Combines predicted TIFFs into a VRT mosaic
â”‚   â””â”€â”€ visualize_predictions.py # Plots inputâ€“GTâ€“prediction triplets
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ ...                      # Saved models, logs, predictions
```

---

![Example Prediction](examples.png)

## ğŸš€ Quick Start

1. **Clone the repo**

```bash
git clone https://github.com/mkovac03/wetland-segmentation.git
cd wetland-segmentation
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **Run training**

```bash
bash run_train.sh
```

4. **Run inference**

```bash
python -m predict.inference --timestamp <TIMESTAMP>
```

---

## ğŸ§  Model Architecture

The model is a **ResNet-UNet-ViT hybrid** that fuses convolutional and attention-based representations for better segmentation of wetlands. It is specifically designed to handle high-dimensional input features and weak supervision labels at fine spatial resolution, with an emphasis on both local texture and global spatial context.

### ğŸ”§ Key Components

* **Encoder**:

  * Based on ResNet-34 (optional ImageNet pretraining)
  * Modified first convolution to accept 29-band embeddings (e.g., temporal and spectral Earth Engine bands)
  * Sequential feature extraction through residual blocks and max pooling

* **Transformer Bottleneck**:

  * A lightweight Vision Transformer (ViT) bottleneck to capture long-range dependencies
  * Operates on a 16Ã—16 feature map, partitioned into 8Ã—8 tokens using a patch size of 2
  * Configured with 4 transformer layers and 8 attention heads
  * Embedding dimension: 512

* **Decoder**:

  * UNet-style upsampling pathway that mirrors the encoder
  * Skip connections between encoder and decoder levels enable spatial detail recovery
  * Each decoder block performs upsampling (via `ConvTranspose2d`) followed by a ReLU activation
  * The final segmentation map is produced via a 1Ã—1 convolution layer and bilinear upsampling to match the original input resolution

---

## ğŸ§ª Data Augmentation

* Implemented via `RandomFlipRotate`:

  * Random horizontal & vertical flips
  * Random 90Â°, 180Â°, 270Â° rotations
  * Applied only during training, not validation/test

---

## ğŸ› ï¸ Loss Function

* **Focal Loss**:

  * Downweights easy negatives and emphasizes hard examples using tunable Î±-Î³ parameters
  * Includes dynamic class weighting and optional boundary masking for edge precision

* **Tversky Loss**:

  * Generalized Dice variant that handles class imbalance with adjustable Î±/Î² weighting
  * Boosts recall for underrepresented and small wetland types

* **Optional Boundary Dice Loss**:

  * Sharpens predictions around fuzzy class edges using distance-transformed masks

* **Combined Objective**:

  * A weighted sum of Focal, Tversky, and optionally Boundary Dice losses
  * Mitigates label imbalance and refines coarse-resolution supervision

---

## ğŸ“Š Evaluation & Outputs

* **Metrics**:

  * Per-class and macro F1, mIoU, pixel accuracy
  * Confusion matrix

---

## ğŸ“ Citation

If you use this in your research, please cite:

> KovÃ¡cs et al. (2025). *High-resolution mapping of wetland types across Europe using CNN-ViT segmentation of satellite embeddings.*

---

## ğŸ“¬ Contact

For questions or collaboration:

* ğŸ§‘â€ğŸ’» [Gyula MÃ¡tÃ© KovÃ¡cs](https://github.com/mkovac03)
* ğŸŒ University of Copenhagen Â· Global Wetland Center
